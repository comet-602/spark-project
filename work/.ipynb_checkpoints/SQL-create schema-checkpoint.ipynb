{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>5</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc.stop()\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "conf = SparkConf().setAppName(\"zzzZ\")\\\n",
    "                  .setMaster(\"spark://10.120.26.200:7077\")\\\n",
    "                  .set(\"spark.executor.memory\", '6g')\\\n",
    "                  .set('spark.cores.max', '4')\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.appName('sql coming~').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+-----+\n",
      "| id|name|age| text|\n",
      "+---+----+---+-----+\n",
      "|  1|Suny| 10|water|\n",
      "|  2|Miya| 30|drink|\n",
      "|  3|Nana| 26|berry|\n",
      "+---+----+---+-----+"
     ]
    }
   ],
   "source": [
    "# RDD創建表 - createDataFrame\n",
    "\n",
    "def create_df_from_rdd():\n",
    "    spark_rdd = spark.sparkContext.parallelize([\n",
    "        (1, \"Suny\", 10, \"water\"),\n",
    "        (2, \"Miya\", 30, \"drink\"),\n",
    "        (3, \"Nana\", 26, \"berry\")])\n",
    " \n",
    "    # 設置屬性\n",
    "    schema = StructType([StructField(\"id\", LongType(), True),\n",
    "                         StructField(\"name\", StringType(), True),\n",
    "                         StructField(\"age\", LongType(), True),\n",
    "                         StructField(\"text\", StringType(), True)])\n",
    "    \n",
    "    # 建立DataFrame\n",
    "    df_from_rdd = spark.createDataFrame(spark_rdd, schema)\n",
    "    \n",
    "    # 建立臨時表\n",
    "    df_from_rdd.createOrReplaceTempView(\"myTempView\")\n",
    "    # 使用SQL\n",
    "    data = spark.sql(\"select * from myTempView\")\n",
    "    data.show()\n",
    "    \n",
    "create_df_from_rdd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+-----+\n",
      "| id|name|age| text|\n",
      "+---+----+---+-----+\n",
      "|  1|Suny| 10|water|\n",
      "|  2|Miya| 30|drink|\n",
      "|  3|Nana| 26|berry|\n",
      "+---+----+---+-----+"
     ]
    }
   ],
   "source": [
    "# RDD創建表 - toDF\n",
    "\n",
    "def create_df_from_rdd():\n",
    "    spark_rdd = spark.sparkContext.parallelize([\n",
    "        (1, \"Suny\", 10, \"water\"),\n",
    "        (2, \"Miya\", 30, \"drink\"),\n",
    "        (3, \"Nana\", 26, \"berry\")])\n",
    " \n",
    "    # 設置屬性\n",
    "    schema = StructType([StructField(\"id\", LongType(), True),\n",
    "                         StructField(\"name\", StringType(), True),\n",
    "                         StructField(\"age\", LongType(), True),\n",
    "                         StructField(\"text\", StringType(), True)])\n",
    "    \n",
    "    # toDF 建立\n",
    "    df_from_rdd = spark_rdd.toDF(schema)\n",
    "    \n",
    "    # 建立臨時表\n",
    "    df_from_rdd.createOrReplaceTempView(\"myTempView\")\n",
    "    # 使用SQL\n",
    "    data = spark.sql(\"select * from myTempView\")\n",
    "    data.show()\n",
    "    \n",
    "create_df_from_rdd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+--------------------+-----+----+-----+\n",
      "|lsoa_code|             borough|      major_category|      minor_category|value|year|month|\n",
      "+---------+--------------------+--------------------+--------------------+-----+----+-----+\n",
      "|E01004563|          Wandsworth|             Robbery|   Personal Property|    0|2008|    6|\n",
      "|E01003496|              Newham|     Criminal Damage|Criminal Damage T...|    0|2013|    9|\n",
      "|E01000086|Barking and Dagenham|  Theft and Handling|  Other Theft Person|    1|2009|    5|\n",
      "|E01001317|              Ealing|            Burglary|Burglary in a Dwe...|    0|2013|    9|\n",
      "|E01000713|             Bromley|Violence Against ...|    Offensive Weapon|    0|2009|   12|\n",
      "|E01000606|               Brent|  Theft and Handling|Motor Vehicle Int...|    0|2015|    9|\n",
      "|E01003211|            Lewisham|  Theft and Handling|  Other Theft Person|    0|2009|   12|\n",
      "|E01003902|Richmond upon Thames|     Criminal Damage|Criminal Damage T...|    0|2013|    3|\n",
      "|E01003264|            Lewisham|Other Notifiable ...|    Other Notifiable|    0|2008|    6|\n",
      "|E01000233|              Barnet|             Robbery|   Business Property|    0|2013|    6|\n",
      "|E01003311|            Lewisham|            Burglary|Burglary in Other...|    0|2014|    2|\n",
      "|E01000098|Barking and Dagenham|            Burglary|Burglary in Other...|    0|2013|    4|\n",
      "|E01000039|Barking and Dagenham|Violence Against ...|          Harassment|    0|2012|   12|\n",
      "|E01000228|              Barnet|               Drugs| Possession Of Drugs|    0|2011|   10|\n",
      "|E01003849|Richmond upon Thames|  Theft and Handling|Theft From Motor ...|    1|2011|    8|\n",
      "|E01003918|           Southwark|     Criminal Damage|Other Criminal Da...|    0|2011|    1|\n",
      "|E01004298|       Tower Hamlets|            Burglary|Burglary in a Dwe...|    0|2016|    3|\n",
      "|E01003862|Richmond upon Thames|Violence Against ...|      Common Assault|    0|2015|    3|\n",
      "|E01000705|             Bromley|     Criminal Damage|Other Criminal Da...|    0|2013|    4|\n",
      "|E01004642|          Wandsworth|               Drugs| Possession Of Drugs|    1|2008|    6|\n",
      "+---------+--------------------+--------------------+--------------------+-----+----+-----+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "# csv創建表\n",
    "\n",
    "def create_df_from_csv():\n",
    "    df_from_csv = spark.read.csv('hdfs://10.120.26.200/user/spark/spark_sql_101/crime/data/', header=True, inferSchema=True)\n",
    "    df_from_csv.show()\n",
    "\n",
    "create_df_from_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+-------------------+-------------------+\n",
      "|                 a|                 b|                  c|                  d|\n",
      "+------------------+------------------+-------------------+-------------------+\n",
      "|0.8960427986988073|0.7928670576246838| 0.1031078979269876|0.20687252992059535|\n",
      "|0.4094078448346632|0.7040344196416706|  0.895674354181298|0.45943575625201927|\n",
      "|0.9560524874171838|0.1214138047234532|0.08448716148312674| 0.2828501644192746|\n",
      "+------------------+------------------+-------------------+-------------------+"
     ]
    }
   ],
   "source": [
    "# pandas創建表\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_df_from_pandas():\n",
    "    df = pd.DataFrame(np.random.random((3, 4)))\n",
    "    df_from_pandas = spark.createDataFrame(df, schema=['a', 'b', 'c', 'd'])\n",
    "    df_from_pandas.show()\n",
    "    \n",
    "create_df_from_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
